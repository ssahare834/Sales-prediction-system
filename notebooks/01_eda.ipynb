{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) - Sales & Stock Data\n",
    "\n",
    "## Objectives:\n",
    "1. Load and inspect the generated datasets\n",
    "2. Check data quality and missing values\n",
    "3. Understand distribution of sales and products\n",
    "4. Identify trends and seasonality\n",
    "5. Analyze correlations and patterns\n",
    "6. Prepare insights for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_products = pd.read_csv('../data/synthetic/products.csv')\n",
    "df_sales = pd.read_csv('../data/synthetic/sales.csv')\n",
    "df_stock = pd.read_csv('../data/synthetic/stock_levels.csv')\n",
    "df_dates = pd.read_csv('../data/synthetic/date_features.csv')\n",
    "\n",
    "# Convert date columns\n",
    "df_sales['date'] = pd.to_datetime(df_sales['date'])\n",
    "df_stock['date'] = pd.to_datetime(df_stock['date'])\n",
    "df_dates['date'] = pd.to_datetime(df_dates['date'])\n",
    "\n",
    "print(\"Datasets loaded successfully!\")\n",
    "print(f\"Products: {len(df_products):,} SKUs\")\n",
    "print(f\"Sales: {len(df_sales):,} records\")\n",
    "print(f\"Stock: {len(df_stock):,} records\")\n",
    "print(f\"Date Features: {len(df_dates):,} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products data quality\n",
    "print(\"=\" * 60)\n",
    "print(\"PRODUCTS DATA QUALITY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {df_products.shape}\")\n",
    "print(f\"\\nMissing Values:\\n{df_products.isnull().sum()}\")\n",
    "print(f\"\\nData Types:\\n{df_products.dtypes}\")\n",
    "print(f\"\\nBasic Statistics:\\n{df_products.describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales data quality\n",
    "print(\"=\" * 60)\n",
    "print(\"SALES DATA QUALITY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {df_sales.shape}\")\n",
    "print(f\"Date Range: {df_sales['date'].min()} to {df_sales['date'].max()}\")\n",
    "print(f\"\\nMissing Values:\\n{df_sales.isnull().sum()}\")\n",
    "print(f\"\\nBasic Statistics:\\n{df_sales.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Product Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Product count by category\n",
    "df_products['category'].value_counts().plot(kind='barh', ax=axes[0])\n",
    "axes[0].set_title('Products by Category', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Products')\n",
    "\n",
    "# Price distribution\n",
    "df_products['price'].hist(bins=30, ax=axes[1], edgecolor='black')\n",
    "axes[1].set_title('Product Price Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Price ($)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive price vs margin analysis\n",
    "fig = px.scatter(df_products, \n",
    "                 x='price', \n",
    "                 y='margin_percent',\n",
    "                 color='category',\n",
    "                 size='base_demand',\n",
    "                 hover_data=['product_id', 'supplier', 'lead_time_days'],\n",
    "                 title='Product Price vs Profit Margin (Size = Base Demand)',\n",
    "                 labels={'price': 'Price ($)', 'margin_percent': 'Margin (%)'})\n",
    "\n",
    "fig.update_layout(height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sales Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sales with product info for enriched analysis\n",
    "df_sales_enriched = df_sales.merge(df_products[['product_id', 'category', 'price']], on='product_id')\n",
    "\n",
    "# Daily aggregated sales\n",
    "daily_sales = df_sales.groupby('date').agg({\n",
    "    'quantity_sold': 'sum',\n",
    "    'revenue': 'sum',\n",
    "    'profit': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"Total Revenue: ${daily_sales['revenue'].sum():,.2f}\")\n",
    "print(f\"Total Profit: ${daily_sales['profit'].sum():,.2f}\")\n",
    "print(f\"Average Daily Revenue: ${daily_sales['revenue'].mean():,.2f}\")\n",
    "print(f\"Average Daily Units Sold: {daily_sales['quantity_sold'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series visualization\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    subplot_titles=('Daily Units Sold', 'Daily Revenue', 'Daily Profit'),\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=daily_sales['date'], y=daily_sales['quantity_sold'], \n",
    "               name='Units Sold', line=dict(color='blue', width=1)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=daily_sales['date'], y=daily_sales['revenue'], \n",
    "               name='Revenue', line=dict(color='green', width=1)),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=daily_sales['date'], y=daily_sales['profit'], \n",
    "               name='Profit', line=dict(color='orange', width=1)),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(height=900, title_text=\"Sales Time Series Overview\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Seasonality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time features to daily sales\n",
    "daily_sales['year'] = daily_sales['date'].dt.year\n",
    "daily_sales['month'] = daily_sales['date'].dt.month\n",
    "daily_sales['day_of_week'] = daily_sales['date'].dt.dayofweek\n",
    "daily_sales['week_of_year'] = daily_sales['date'].dt.isocalendar().week\n",
    "\n",
    "# Monthly patterns\n",
    "monthly_avg = daily_sales.groupby('month')['revenue'].mean().reset_index()\n",
    "monthly_avg['month_name'] = pd.to_datetime(monthly_avg['month'], format='%m').dt.month_name()\n",
    "\n",
    "fig = px.bar(monthly_avg, x='month_name', y='revenue',\n",
    "             title='Average Revenue by Month',\n",
    "             labels={'month_name': 'Month', 'revenue': 'Average Revenue ($)'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of week patterns\n",
    "dow_avg = daily_sales.groupby('day_of_week')['revenue'].mean().reset_index()\n",
    "dow_avg['day_name'] = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "fig = px.bar(dow_avg, x='day_name', y='revenue',\n",
    "             title='Average Revenue by Day of Week',\n",
    "             labels={'day_name': 'Day', 'revenue': 'Average Revenue ($)'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Category Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category-wise sales\n",
    "category_sales = df_sales_enriched.groupby('category').agg({\n",
    "    'quantity_sold': 'sum',\n",
    "    'revenue': 'sum',\n",
    "    'profit': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "category_sales = category_sales.sort_values('revenue', ascending=False)\n",
    "\n",
    "fig = px.bar(category_sales, x='category', y='revenue',\n",
    "             title='Total Revenue by Category',\n",
    "             labels={'category': 'Category', 'revenue': 'Total Revenue ($)'})\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Top Products Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 products by revenue\n",
    "product_sales = df_sales.groupby('product_id').agg({\n",
    "    'quantity_sold': 'sum',\n",
    "    'revenue': 'sum',\n",
    "    'profit': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "product_sales = product_sales.merge(df_products[['product_id', 'category', 'price']], on='product_id')\n",
    "top_products = product_sales.nlargest(20, 'revenue')\n",
    "\n",
    "fig = px.bar(top_products, x='product_id', y='revenue',\n",
    "             color='category',\n",
    "             title='Top 20 Products by Revenue',\n",
    "             labels={'product_id': 'Product ID', 'revenue': 'Total Revenue ($)'})\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nTop 10 Products:\")\n",
    "print(top_products[['product_id', 'category', 'revenue', 'profit']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Stock Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder frequency by product\n",
    "reorder_analysis = df_stock.groupby('product_id').agg({\n",
    "    'reorder_triggered': 'sum',\n",
    "    'stock_level': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "reorder_analysis.columns = ['product_id', 'total_reorders', 'avg_stock_level']\n",
    "reorder_analysis = reorder_analysis.merge(df_products[['product_id', 'category']], on='product_id')\n",
    "\n",
    "fig = px.scatter(reorder_analysis, \n",
    "                 x='avg_stock_level', \n",
    "                 y='total_reorders',\n",
    "                 color='category',\n",
    "                 hover_data=['product_id'],\n",
    "                 title='Average Stock Level vs Reorder Frequency',\n",
    "                 labels={'avg_stock_level': 'Average Stock Level', \n",
    "                        'total_reorders': 'Total Reorders'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations in product data\n",
    "numeric_cols = ['price', 'cost', 'margin_percent', 'base_demand', \n",
    "                'seasonality_strength', 'promotion_sensitivity', 'lead_time_days']\n",
    "\n",
    "correlation_matrix = df_products[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Product Features Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights & Recommendations\n",
    "\n",
    "### Data Quality:\n",
    "- No missing values in critical columns\n",
    "- Date range covers 3 years (sufficient for seasonal analysis)\n",
    "- ~104K sales records provide robust dataset\n",
    "\n",
    "### Patterns Observed:\n",
    "1. **Seasonality**: Clear monthly and weekly patterns visible\n",
    "2. **Categories**: Electronics and Toys show highest revenue\n",
    "3. **Trends**: Overall growth trend visible in sales\n",
    "4. **Promotions**: Significant impact on sales volume\n",
    "\n",
    "### Next Steps for Modeling:\n",
    "1. Feature engineering: Create lag features, rolling statistics\n",
    "2. Handle outliers during promotional periods\n",
    "3. Split data: Train (2022-2023), Validation (Jan-Jun 2024), Test (Jul-Dec 2024)\n",
    "4. Prepare separate models for different product categories\n",
    "5. Consider ensemble approaches for better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key statistics for reference\n",
    "summary_stats = {\n",
    "    'total_products': len(df_products),\n",
    "    'total_sales_records': len(df_sales),\n",
    "    'date_range': f\"{df_sales['date'].min()} to {df_sales['date'].max()}\",\n",
    "    'total_revenue': df_sales['revenue'].sum(),\n",
    "    'total_profit': df_sales['profit'].sum(),\n",
    "    'avg_daily_revenue': daily_sales['revenue'].mean(),\n",
    "    'top_category': category_sales.iloc[0]['category'],\n",
    "    'categories': df_products['category'].nunique()\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
